{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2140dea1",
   "metadata": {},
   "source": [
    "# Tree Methods Code Along\n",
    "\n",
    "In this lecture we will code along with some data and test out 3 different tree methods:\n",
    "\n",
    "* A single decision tree\n",
    "* A random forest\n",
    "* A gradient boosted tree classifier\n",
    "    \n",
    "We will be using a college dataset to try to classify colleges as Private or Public based off these features:\n",
    "\n",
    "    Private A factor with levels No and Yes indicating private or public university\n",
    "    Apps Number of applications received\n",
    "    Accept Number of applications accepted\n",
    "    Enroll Number of new students enrolled\n",
    "    Top10perc Pct. new students from top 10% of H.S. class\n",
    "    Top25perc Pct. new students from top 25% of H.S. class\n",
    "    F.Undergrad Number of fulltime undergraduates\n",
    "    P.Undergrad Number of parttime undergraduates\n",
    "    Outstate Out-of-state tuition\n",
    "    Room.Board Room and board costs\n",
    "    Books Estimated book costs\n",
    "    Personal Estimated personal spending\n",
    "    PhD Pct. of faculty with Ph.D.’s\n",
    "    Terminal Pct. of faculty with terminal degree\n",
    "    S.F.Ratio Student/faculty ratio\n",
    "    perc.alumni Pct. alumni who donate\n",
    "    Expend Instructional expenditure per student\n",
    "    Grad.Rate Graduation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5754e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree methods Example\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('treecode').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07170627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "data = spark.read.csv('./data/College.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86482b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ebc63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(School='Abilene Christian University', Private='Yes', Apps=1660, Accept=1232, Enroll=721, Top10perc=23, Top25perc=52, F_Undergrad=2885, P_Undergrad=537, Outstate=7440, Room_Board=3300, Books=450, Personal=2200, PhD=70, Terminal=78, S_F_Ratio=18.1, perc_alumni=12, Expend=7041, Grad_Rate=60)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123a917",
   "metadata": {},
   "source": [
    "### Spark Formatting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b8f5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few things we need to do before Spark can accept the data!\n",
    "# It needs to be in the form of two columns\n",
    "# (\"label\",\"features\")\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d7b2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['School',\n",
       " 'Private',\n",
       " 'Apps',\n",
       " 'Accept',\n",
       " 'Enroll',\n",
       " 'Top10perc',\n",
       " 'Top25perc',\n",
       " 'F_Undergrad',\n",
       " 'P_Undergrad',\n",
       " 'Outstate',\n",
       " 'Room_Board',\n",
       " 'Books',\n",
       " 'Personal',\n",
       " 'PhD',\n",
       " 'Terminal',\n",
       " 'S_F_Ratio',\n",
       " 'perc_alumni',\n",
       " 'Expend',\n",
       " 'Grad_Rate']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce8c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['Apps',\n",
    " 'Accept',\n",
    " 'Enroll',\n",
    " 'Top10perc',\n",
    " 'Top25perc',\n",
    " 'F_Undergrad',\n",
    " 'P_Undergrad',\n",
    " 'Outstate',\n",
    " 'Room_Board',\n",
    " 'Books',\n",
    " 'Personal',\n",
    " 'PhD',\n",
    " 'Terminal',\n",
    " 'S_F_Ratio',\n",
    " 'perc_alumni',\n",
    " 'Expend',\n",
    " 'Grad_Rate'],outputCol= 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f65126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d5dc0",
   "metadata": {},
   "source": [
    "Deal with Private column being \"yes\" or \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "528c0acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "233ec360",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol= 'Private',outputCol = 'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d01f3ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fixed = indexer.fit(output).transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "326e57bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- School: string (nullable = true)\n",
      " |-- Private: string (nullable = true)\n",
      " |-- Apps: integer (nullable = true)\n",
      " |-- Accept: integer (nullable = true)\n",
      " |-- Enroll: integer (nullable = true)\n",
      " |-- Top10perc: integer (nullable = true)\n",
      " |-- Top25perc: integer (nullable = true)\n",
      " |-- F_Undergrad: integer (nullable = true)\n",
      " |-- P_Undergrad: integer (nullable = true)\n",
      " |-- Outstate: integer (nullable = true)\n",
      " |-- Room_Board: integer (nullable = true)\n",
      " |-- Books: integer (nullable = true)\n",
      " |-- Personal: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Terminal: integer (nullable = true)\n",
      " |-- S_F_Ratio: double (nullable = true)\n",
      " |-- perc_alumni: integer (nullable = true)\n",
      " |-- Expend: integer (nullable = true)\n",
      " |-- Grad_Rate: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- PrivateIndex: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_fixed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68d5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output_fixed.select('features','PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50d2bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae8a38",
   "metadata": {},
   "source": [
    "### The Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbcb9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6858ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82475eb9",
   "metadata": {},
   "source": [
    "**RandomForestClassifier:**\n",
    "- Utilizado para problemas de clasificación.\n",
    "- La variable objetivo es categórica, es decir, tiene etiquetas o clases discretas.\n",
    "- Ejemplos de problemas de clasificación incluyen la clasificación de correos electrónicos como spam o no spam, la identificación de imágenes de gatos o perros, etc.\n",
    "\n",
    "**RandomForestRegressor:**\n",
    "- Utilizado para problemas de regresión.\n",
    "- La variable objetivo es numérica, es decir, tiene valores continuos.\n",
    "- Ejemplos de problemas de regresión incluyen la predicción de precios de viviendas, la estimación de ingresos, etc.\n",
    "\n",
    "**Pipeline**\n",
    "En PySpark, un Pipeline es una secuencia de etapas (stages) que se encadenan para ejecutar de manera ordenada un conjunto de operaciones en un flujo de trabajo de procesamiento de datos. Cada etapa en el pipeline puede ser una transformación de datos o un modelo de aprendizaje automático, y el pipeline proporciona una forma de organizar y ejecutar estas etapas de manera eficiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4441930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol = 'PrivateIndex',featuresCol= 'features')\n",
    "rfc = RandomForestClassifier(labelCol = 'PrivateIndex',featuresCol= 'features')\n",
    "gbt = GBTClassifier(labelCol = 'PrivateIndex',featuresCol= 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "205548eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar a los modelos\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3a0ee",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "Let's compare each of these models!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2424a6de",
   "metadata": {},
   "source": [
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfc_preds = rfc_model.transform(test_data)\n",
    "gbt_preds = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1c7e3",
   "metadata": {},
   "source": [
    "**Evaluation Metrics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "397509cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c186750",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'PrivateIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5694085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.8818934688499905\n"
     ]
    }
   ],
   "source": [
    "print('DTC')\n",
    "print(my_binary_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3cb276c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "0.977131564088086\n"
     ]
    }
   ],
   "source": [
    "print('RFC')\n",
    "print(my_binary_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e421df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT\n",
      "0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "print('GBT')\n",
    "print(my_binary_eval.evaluate(gbt_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f91e26",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2680e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00daa6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='PrivateIndex',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "559deb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.8878923766816144\n"
     ]
    }
   ],
   "source": [
    "print('DTC')\n",
    "print(acc_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "284ef308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "0.9192825112107623\n"
     ]
    }
   ],
   "source": [
    "print('RFC')\n",
    "print(acc_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca96425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT\n",
      "0.8834080717488789\n"
     ]
    }
   ],
   "source": [
    "print('GBT')\n",
    "print(acc_eval.evaluate(gbt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4395ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436b822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22285f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816fd056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1d6a314",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
